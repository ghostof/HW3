{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COGS109\n",
    "# Homework 4\n",
    "# Gustav Sto. Tomas\n",
    "# A15358078\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.tseries\n",
    "from pandas.core import datetools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "df = pd.read_csv('hw3_divseq_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a\n",
    "logreg2 = smf.logit(formula = 'mature ~ Lars2 + Malat1', data=df).fit()\n",
    "print(logreg2.summary())\n",
    "print(logreg2.pvalues)\n",
    "pred_both = df[['Lars2','Malat1']]\n",
    "\n",
    "df['pred_both'] = logreg2.predict(pred_both)\n",
    "df['pred_both_mature'] = 1*(df.pred_both > 0.5)\n",
    "df['pred_both_immature'] = 1 *(df.pred_both < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[618  34]\n",
      " [ 45 120]]\n",
      "[[   0.    0.    1.]\n",
      " [   0.  618.   34.]\n",
      " [   1.   45.  120.]]\n",
      "               pred_immature  pred_mature\n",
      "true_immature            618           34\n",
      "true_mature               45          120\n",
      "\n",
      "\n",
      "correctly predicted mature (TP): 120\n",
      "correctly predicted immature (TN): 618\n",
      "correctly predicted: 738\n",
      "correctly predicted: 0.903304773562\n"
     ]
    }
   ],
   "source": [
    "# 2a : confusion matrix\n",
    "\n",
    "conf_mat = confusion_matrix(df.mature, df.pred_both_mature,)\n",
    "print(conf_mat)\n",
    "\n",
    "ok = np.zeros((3,3))\n",
    "#print(ok)\n",
    "ok[0,2] = 1\n",
    "ok[2,0] = 1\n",
    "ok[1,1] = conf_mat[0,0]\n",
    "ok[1,2] = conf_mat[0,1]\n",
    "ok[2,1] = conf_mat[1,0]\n",
    "ok[2,2] = conf_mat[1,1]\n",
    "print(ok)\n",
    "\n",
    "con = pd.DataFrame(data=conf_mat, index=['true_immature','true_mature'],columns=['pred_immature','pred_mature'])\n",
    "print(con)\n",
    "\n",
    "\n",
    "correct_m = conf_mat[1,1]\n",
    "correct_im = conf_mat[0,0]\n",
    "correct = conf_mat[0,0]+conf_mat[1,1]\n",
    "print()\n",
    "print()\n",
    "print('correctly predicted mature (TP):', correct_m)\n",
    "print('correctly predicted immature (TN):', correct_im)\n",
    "print('correctly predicted:', correct)\n",
    "print('correctly predicted:', correct/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix with threshold 0.2:\n",
      "               pred_immature  pred_mature\n",
      "true_immature            575           77\n",
      "true_mature                7          158\n",
      "\n",
      "Sensitivity 0.2: 0.957575757576\n",
      "Specificity 0.2: 0.881901840491\n",
      "with a threshold of 0.2, specificity is somewhat lower, but sensitivity is very high, meaning fewer false positives\n",
      "\n",
      "confusion_matrix with threshold 0.8:\n",
      "               pred_immature  pred_mature\n",
      "true_immature            643            9\n",
      "true_mature               90           75\n",
      "\n",
      "Sensitivity 0.8: 0.454545454545\n",
      "Specificity 0.8: 0.986196319018\n",
      "with a threshold of 0.8, specificity is somewhat higher but sensitivity is much lower, meaning more false negatives.\n",
      "\n",
      "more actually mature neurons are correctly classified as mature with a threshold of 0.2. a threshold of 0.8 instead classifies even more of the immature neurons correctly than the bayesian (0.5) classifier died, but many more mature neurons are falsely classified as immature (false negatives). since we want to make better classifications for mature neurons, a threshold of 0.2 is to prefer.\n"
     ]
    }
   ],
   "source": [
    "#2 b and c\n",
    "\n",
    "df['pred_both_20'] = 1*(df.pred_both > 0.2)\n",
    "df['pred_both_80'] = 1*(df.pred_both > 0.8)\n",
    "\n",
    "\n",
    "\n",
    "conf_mat2 = confusion_matrix(df.mature, df.pred_both_20,)\n",
    "#print(conf_mat2)\n",
    "\n",
    "conf_mat8 = confusion_matrix(df.mature, df.pred_both_80,)\n",
    "#print(conf_mat8)\n",
    "\n",
    "con2 = pd.DataFrame(data=conf_mat2, index=['true_immature','true_mature'],columns=['pred_immature','pred_mature'])\n",
    "print('confusion matrix with threshold 0.2:')\n",
    "print(con2)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "specificity2 = conf_mat2[0][0]/(conf_mat2[0][0]+conf_mat2[0][1])\n",
    "sensitivity2 = conf_mat2[1][1]/(conf_mat2[1][0]+conf_mat2[1][1])\n",
    "\n",
    "#sensitivity2 = conf_mat2[0,0]/(conf_mat2[0,0]+conf_mat2[0,1])\n",
    "print(\"Sensitivity 0.2: \" + str(sensitivity2))\n",
    "#specificity2 = conf_mat2[1,1]/(conf_mat2[1,0]+conf_mat2[1,1])\n",
    "print(\"Specificity 0.2: \" + str(specificity2))\n",
    "print('with a threshold of 0.2, specificity is somewhat lower, but sensitivity is very high, meaning fewer false positives')\n",
    "\n",
    "print()\n",
    "\n",
    "con8 = pd.DataFrame(data=conf_mat8, index=['true_immature','true_mature'],columns=['pred_immature','pred_mature'])\n",
    "print('confusion_matrix with threshold 0.8:')\n",
    "print(con8)\n",
    "print()\n",
    "\n",
    "\n",
    "specificity8 = conf_mat8[0][0]/(conf_mat8[0][0]+conf_mat8[0][1])\n",
    "sensitivity8 = conf_mat8[1][1]/(conf_mat8[1][0]+conf_mat8[1][1])\n",
    "\n",
    "#sensitivity8 = conf_mat8[0,0]/(conf_mat8[0,0]+conf_mat8[0,1])\n",
    "print(\"Sensitivity 0.8: \" + str(sensitivity8))\n",
    "#specificity8 = conf_mat8[1,1]/(conf_mat8[1,0]+conf_mat8[1,1])\n",
    "print(\"Specificity 0.8: \" + str(specificity8))\n",
    "print('with a threshold of 0.8, specificity is somewhat higher but sensitivity is much lower, meaning more false negatives.')\n",
    "print()\n",
    "print('more actually mature neurons are correctly classified as mature with a threshold of 0.2. a threshold of 0.8 instead classifies even more of the immature neurons correctly than the bayesian (0.5) classifier died, but many more mature neurons are falsely classified as immature (false negatives). since we want to make better classifications for mature neurons, a threshold of 0.2 is to prefer.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some test stuff\n",
    "\n",
    "falseP = []\n",
    "threshold = np.arange(0,1,0.1)\n",
    "for i in range(len(threshold)):\n",
    "    cat_labels = 1*(df.pred_both > threshold[i])\n",
    "    cons = confusion_matrix(df.mature,cat_labels)\n",
    "    specificity = cons[0][0]/(cons[0][0]+cons[0][1])\n",
    "    sensitivity = cons[1][1]/(cons[1][0]+cons[1][1])\n",
    "    #sensitivity = cons[0,0]/(cons[0,0]+cons[0,1])\n",
    "    #specificity = cons[1,1]/(cons[1,0]+cons[1,1])\n",
    "    fpr = 1-specificity\n",
    "    tpr = sensitivity\n",
    "    falseP.append(fpr)\n",
    "    #print(fpr)\n",
    "    print(cons)\n",
    "\n",
    "print(falseP)\n",
    "    \n",
    "\n",
    "trueP = []\n",
    "threshold = np.arange(0,1,0.1)\n",
    "for i in range(len(threshold)):\n",
    "    cat_labels = 1*(df.pred_both < threshold[i])\n",
    "    cons = confusion_matrix(df.mature,cat_labels)\n",
    "    specificity = cons[0][0]/(cons[0][0]+cons[0][1])\n",
    "    sensitivity = cons[1][1]/(cons[1][0]+cons[1][1])\n",
    "    #sensitivity = cons[0,0]/(cons[0,0]+cons[0,1])\n",
    "    #specificity = cons[1,1]/(cons[1,0]+cons[1,1])\n",
    "    fpr = 1-specificity\n",
    "    tpr = sensitivity\n",
    "    trueP.append(tpr)\n",
    "    #print(tpr)\n",
    "    print(cons)\n",
    "\n",
    "print(trueP)    \n",
    "    \n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_autoscale_on(False)\n",
    "plt.plot(threshold,falseP)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('false positive rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "f = lambda x: falseP\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_autoscale_on(False)\n",
    "plt.plot(threshold,trueP)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_autoscale_on(False)\n",
    "plt.plot(falseP,trueP)\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conf = confusion_matrix(df.mature,cat_labels)\n",
    "print(conf)\n",
    "print(len(df.mature)-conf[0,1])\n",
    "sensitivity = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "specificity = conf[0][0]/(conf[0][0]+conf[0][1])\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 d, e, and f\n",
    "\n",
    "y = df.mature\n",
    "scores = df.pred_both\n",
    "fpr, tpr, thresholds = roc_curve(y, scores)#, cat_labels)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(thresholds,fpr)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('false positive rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(thresholds,tpr)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "#plt.plot(roc_curve(y,scores))\n",
    "plt.plot(fpr,tpr,'r.')\n",
    "#ax.scatter(df.pred_both,roc_curve(df.mature,df.pred_both))\n",
    "#plt.plot(thresholds==0.5, 'b-')\n",
    "#for i in range(len(thresholds)):\n",
    "#    if thresholds[i] > 0.5 < 0.51:\n",
    "#        plt.plot(fpr, tpr, marker='o', markersize=3, color=\"blue\")\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"fig,ax = plt.subplots()\n",
    "#plt.plot(roc_curve(y,scores))\n",
    "plt.plot(fpr,tpr,'r.')\n",
    "#ax.scatter(df.pred_both,roc_curve(df.mature,df.pred_both))\n",
    "#plt.plot(thresholds==0.5, 'b-')\n",
    "#for i in range(len(thresholds)):\n",
    "    cats = 1*(scores > thresholds[i])\n",
    "    #if thresholds[i] > 0.5 < 0.51:\n",
    "    #plt.plot(cats,'b.')#, marker='o', markersize=0.01, color=\"blue\")\n",
    "    #for i in cats:\n",
    "    #    if scores == 0.5\n",
    "    #        plt.plot(fpr,tpr,'b.')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = lambda n: (1-(1-1/n)^n)\n",
    "x = np.arange(1,100000)\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(x,p(x))\n",
    "plt.show()\n",
    "\n",
    "#pr = function(n) return(1 - (1 - 1/n)^n)\n",
    "#x = 1:1e+05\n",
    "#plot(x, pr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
